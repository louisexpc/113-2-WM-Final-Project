{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session Generator Without Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r13946024/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "import pandas as pd\n",
    "from utils import load_pickle\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_name(raw_output, fallback=\"Unknown Product\"):\n",
    "    # Split the response into lines\n",
    "    lines = raw_output.strip().split(\"\\n\")\n",
    "\n",
    "    # Find the last non-empty line\n",
    "    for line in reversed(lines):\n",
    "        clean_line = line.strip()\n",
    "        if clean_line:\n",
    "            # Remove common prefixes\n",
    "            for prefix in [\"Sure,\", \"Here is\", \"Here are\", \"Of course,\", \"I'd be happy to help!\"]:\n",
    "                if clean_line.lower().startswith(prefix.lower()):\n",
    "                    clean_line = clean_line[len(prefix):].strip()\n",
    "            # Remove category hints if present\n",
    "            clean_line = re.sub(r'for the \".+?\" category', \"\", clean_line).strip()\n",
    "            \n",
    "            # Return the cleaned line if it looks like a product name\n",
    "            if clean_line and len(clean_line.split()) >= 2:\n",
    "                return clean_line\n",
    "\n",
    "    # Fallback if no valid name is found\n",
    "    print(f\"⚠️ No valid product name found in: '{raw_output}'\")\n",
    "    return fallback\n",
    "\n",
    "# === Extract a Python List from LLM Output ===\n",
    "def extract_list_from_text(text, fallback=None):\n",
    "    if not text or not isinstance(text, str):\n",
    "        print(\"⚠️ Invalid input. Using fallback.\")\n",
    "        return fallback or []\n",
    "\n",
    "    # Strip leading instructions and whitespace\n",
    "    cleaned_text = text.strip()\n",
    "\n",
    "    # Extract the first valid list\n",
    "    match = re.search(r'\\[\\s*(?:[^\\[\\]]|\\[[^\\[\\]]*\\])*\\s*\\]', cleaned_text, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            extracted = match.group(0).replace(\"\\n\", \"\").replace(\"    \", \"\").strip()\n",
    "            # Basic sanity check to avoid explanation leakage\n",
    "            if extracted.startswith(\"[\") and extracted.endswith(\"]\"):\n",
    "                return ast.literal_eval(extracted)\n",
    "            else:\n",
    "                print(\"⚠️ Unexpected non-list format. Using fallback.\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Parsing failed: {e}\")\n",
    "    \n",
    "    print(\"⚠️ No valid list found. Using fallback.\")\n",
    "    return fallback or []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II Functions & Prompts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## prompt #1: Get Categories form History Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories_from_history(history_str, category_list, n=9):\n",
    "    categories_str = \", \".join(category_list)\n",
    "    # Define the system and user prompts\n",
    "    system_prompt = \"You are a fashion recommendation assistant.\"\n",
    "    user_prompt = f\"\"\"\n",
    "    Given this purchase history:\n",
    "    {history_str}\n",
    "\n",
    "    Select exactly {n} categories from the following list:\n",
    "    {categories_str}\n",
    "\n",
    "    ⚠️ Respond **only** with a Python list of exactly {n} categories, **without any additional text, punctuation, or explanations.**\n",
    "\n",
    "    ✅ Format exactly like this:\n",
    "    [\"Category1\", \"Category2\", \"Category3\", ..., \"Category{n}\"]\n",
    "\n",
    "    ❗ Do not add any introductory words, explanations, or context.\n",
    "    ❗ Do not include line breaks within the list.\n",
    "    ❗ Do not add extra punctuation or bullet points.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{user_prompt} [/INST]\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=128)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    response = response.split(\"[/INST]\")[-1].strip()\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt #2: Generate New Session from Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def get_user_info(user_id: str, user_dataset: pd.DataFrame):\n",
    "    user_info = user_dataset[user_dataset[\"customer_id\"] == user_id]\n",
    "    return user_info\n",
    "\n",
    "def get_current_season():\n",
    "    current_date = datetime.now()\n",
    "    current_month = current_date.month\n",
    "    if current_month in [12, 1, 2]:\n",
    "        current_season = \"Winter\"\n",
    "    elif current_month in [3, 4, 5]:\n",
    "        current_season = \"Spring\"\n",
    "    elif current_month in [6, 7, 8]:\n",
    "        current_season = \"Summer\"\n",
    "    else:\n",
    "        current_season = \"Autumn\"\n",
    "    \n",
    "    return current_season\n",
    "\n",
    "\n",
    "def get_category_examples(category):\n",
    "    \"\"\"\n",
    "    從 CSV 檔案中讀取特定類別的商品名稱範例\n",
    "    \n",
    "    Args:\n",
    "        category (str): 商品類別名稱\n",
    "        \n",
    "    Returns:\n",
    "        str: 該類別的商品名稱範例，以逗號分隔\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 讀取 CSV 檔案，指定分隔符為 ':'\n",
    "        category_examples = pd.read_csv(\"data/product_name_examples.csv\", \n",
    "                                      sep=':', \n",
    "                                      names=['category', 'examples'])\n",
    "        \n",
    "        # 找到對應類別並回傳範例\n",
    "        examples = category_examples[category_examples[\"category\"] == category][\"examples\"].values\n",
    "        \n",
    "        if len(examples) == 0:\n",
    "            print(f\"⚠️ 找不到類別 '{category}' 的範例\")\n",
    "            return \"\"\n",
    "            \n",
    "        return examples[0]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 讀取範例時發生錯誤: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_from_category(category, user_info: pd.DataFrame):\n",
    "    \n",
    "    current_season = get_current_season()\n",
    "    \n",
    "    # Define the system and user prompts\n",
    "    system_prompt = \"You are a fashion product naming assistant.\"\n",
    "    user_prompt = f\"\"\"\n",
    "    Customer information:\n",
    "    - Age: {user_info[\"age\"]}\n",
    "    - Subcription to fashion magazines: {user_info[\"fashion_news_frequency\"]}\n",
    "    - Club membership: {user_info[\"club_member_status\"]}\n",
    "    \n",
    "    Category: {category}\n",
    "    Season: {current_season}\n",
    "    Generate a realistic product name that:\n",
    "       1. Clearly belongs to the {category} category\n",
    "       2. Is appropriate for {current_season}\n",
    "       \n",
    "    Examples for {category}:\n",
    "       {get_category_examples(category)}\n",
    "    \n",
    "    ⚠️ **Output Requirements:**  \n",
    "    - Respond with only the product name as a single line of text.  \n",
    "    - Do not include quotes, bullet points, or explanations.  \n",
    "    \"\"\"\n",
    "\n",
    "    # Construct the full prompt\n",
    "    full_prompt = f\"<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{user_prompt.strip()} [/INST]\"\n",
    "\n",
    "    # Generate the response\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=128)\n",
    "\n",
    "    # Decode and return the response\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    response = response.split(\"[/INST]\")[-1].strip()\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_from_categories(category_dict: dict[str, list[str]], user_info: pd.DataFrame) -> dict[str, list[str]]:\n",
    "    \"\"\"為每個使用者的每個類別生成對應的商品名稱\n",
    "    \n",
    "    Args:\n",
    "        category_dict: {user_id: [category1, category2, ...]}\n",
    "        user_info: 使用者資料，包含 age, fashion_news_frequency, club_member_status\n",
    "        \n",
    "    Returns:\n",
    "        dict[str, list[str]]: {user_id: [product_name1, product_name2, ...]}\n",
    "        每個 product_name 對應 category_dict 中相同位置的 category\n",
    "    \"\"\"\n",
    "    current_season = get_current_season()\n",
    "    result = {}\n",
    "    \n",
    "    for user_id, categories in category_dict.items():\n",
    "        if user_info.empty:\n",
    "            print(f\"⚠️ No user info found for {user_id}\")\n",
    "            result[user_id] = [\"Unknown\"] * len(categories)\n",
    "            continue\n",
    "        \n",
    "        product_names = []\n",
    "        \n",
    "        for category in categories:\n",
    "            \n",
    "            # 為這個使用者的所有類別生成商品名稱\n",
    "            system_prompt = \"\"\"You are a fashion product naming assistant. \n",
    "                            You MUST:\n",
    "                            1. Output ONLY ONE product name\n",
    "                            2. Follow the format strictly\n",
    "                            3. Never include explanations\n",
    "                            4. Never include quotes or brackets\n",
    "                            5. Never include emojis\n",
    "                            6. Never include any other text like \"Sure, here is a product name for a jacket that meets the requirements:\"\n",
    "\n",
    "                            If you fail to follow these rules, the output will be rejected.\"\"\"\n",
    "            user_prompt = f\"\"\"\n",
    "            Generate **ONE** product name for {category} that is:\n",
    "            1. Appropriate for {current_season}, But not too specific and do not include season in the name\n",
    "            2. 2-4 words long\n",
    "            3. Unique and creative\n",
    "\n",
    "            Customer context:\n",
    "            - Age: {user_info[\"age\"]}\n",
    "            - Fashion magazine subscription: {user_info[\"fashion_news_frequency\"]}\n",
    "            - Club status: {user_info[\"club_member_status\"]}\n",
    "\n",
    "            Example: {get_category_examples(category)}\n",
    "\n",
    "            ⚠️ CRITICAL: Output ONLY **ONE** product name. No explanations, quotes, or additional text.\n",
    "            Format: Product Name\n",
    "            \"\"\"\n",
    "        \n",
    "            # 生成回應\n",
    "            full_prompt = f\"<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{user_prompt.strip()} [/INST]\"\n",
    "            inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "            outputs = model.generate(**inputs, max_new_tokens=256, temperature=0.3, do_sample=True)  # 增加 token 數以容納多個名稱\n",
    "            response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "            response = response.split(\"[/INST]\")[-1].strip()\n",
    "            print(f\"Response for {user_id} - {category}:\")\n",
    "            print(response)\n",
    "            print(\"===\" * 20)\n",
    "        \n",
    "        # 解析回應\n",
    "            product_name = extract_product_name(response, fallback=f\"Unknown {category}\")\n",
    "            product_names.append(product_name)\n",
    "        result[user_id] = product_names\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils Function\n",
    "\n",
    "- **prefilter_categories(items_list, category_list, top_k=20)**\n",
    "\n",
    "    此函式用於在進入 LLM 前，根據使用者歷史購買商品所對應的 product type（商品類別），從所有可選類別中預先篩選出最相關的前 top_k 個類別，避免因為類別數量過多導致超出 LLM 的上下文長度限制（context window overflow）。\n",
    "\n",
    "- **article_to_product_type(article_id)**\n",
    "\n",
    "    此函式將 articleId 轉換成相對應的 product type (category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Pre-Filter Categories with Embeddings ===\n",
    "def prefilter_categories(items_list, category_list, top_k=20):\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Encode the history as a single vector\n",
    "    history_embedding = model.encode(items_list, convert_to_tensor=True)\n",
    "    \n",
    "    # Encode all categories\n",
    "    category_embeddings = model.encode(category_list, convert_to_tensor=True)\n",
    "    \n",
    "    # Compute similarity\n",
    "    cos_scores = util.cos_sim(history_embedding, category_embeddings)[0]\n",
    "    top_results = cos_scores.topk(k=top_k)\n",
    "    \n",
    "    # Extract top-K categories\n",
    "    top_categories = [category_list[i] for i in top_results.indices]\n",
    "    top_scores = [cos_scores[i].item() for i in top_results.indices]\n",
    "    \n",
    "    # Return as a dictionary for better interpretability\n",
    "    return top_categories\n",
    "\n",
    "\n",
    "def article_to_product_type(article_id):\n",
    "    mapping = load_pickle(\"data/article_to_product_mapping.pkl\")\n",
    "    return mapping.get(article_id, \"Unknown Product Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Pipeline\n",
    "\n",
    "**enrich_user_session(user_sessions, category_list, n=9, max_history_length=10)**\n",
    "\n",
    "這個函式是整個推薦系統流程的核心，它的目的在於將原本的使用者購買紀錄 user session 擴充為更完整、更擬真的購物序列，藉由語意相似度 + LLM 輔助推理生成更多合理的商品。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Generate a New Enriched User Session ===\n",
    "def enrich_user_session(user_sessions, customer_df, category_list, n=9, max_history_length=10):\n",
    "    session = {uid: items.copy() for uid, items in user_sessions.items()}\n",
    "\n",
    "    for uid, items in session.items():\n",
    "        # Convert item IDs to product names\n",
    "        history_str = \" \".join([article_to_product_type(item) for item in items])\n",
    "        print(f\"User: {uid}, History: {history_str}\\n\")\n",
    "        top_categories = prefilter_categories(history_str, category_list, top_k=20)\n",
    "        print(f\"Top categories: {top_categories}\\n\")\n",
    "        # Generate Categories\n",
    "        raw_output = get_categories_from_history(history_str, top_categories)\n",
    "        print(\"LLM raw output:\", raw_output, \"\\n\")\n",
    "        print(\"End of the output\")\n",
    "        categories = extract_list_from_text(raw_output, fallback=[\"tops\", \"accessories\", \"shoes\"])\n",
    "        print(f\"Selected Categories: {categories}\\n\")\n",
    "\n",
    "        user_info = get_user_info(uid, customer_df)\n",
    "        \n",
    "        # Generate Items for Each Category\n",
    "        while len(items) < max_history_length:\n",
    "            for category in categories:\n",
    "                raw_item = get_item_from_category(category, user_info)\n",
    "                print(\"Raw item LLM output: \\n\", raw_item)\n",
    "                item = extract_product_name(raw_item, fallback=\"Unkown\")\n",
    "                print(\"Extracted: \", item)\n",
    "                if len(items) > 0:\n",
    "                    items.insert(-1, item)\n",
    "                else:\n",
    "                    # If the list is empty, just append\n",
    "                    items.append(item)\n",
    "                if len(items) >= max_history_length:\n",
    "                    break\n",
    "\n",
    "    return session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load Category List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total categories loaded: 131\n",
      "Sample categories: ['Vest top', 'Bra', 'Underwear Tights', 'Socks', 'Leggings/Tights', 'Sweater', 'Top', 'Trousers', 'Hair clip', 'Umbrella']\n",
      "0              ACTIVE\n",
      "1              ACTIVE\n",
      "2              ACTIVE\n",
      "3              ACTIVE\n",
      "4              ACTIVE\n",
      "              ...    \n",
      "1371975        ACTIVE\n",
      "1371976        ACTIVE\n",
      "1371977        ACTIVE\n",
      "1371978        ACTIVE\n",
      "1371979    PRE-CREATE\n",
      "Name: club_member_status, Length: 1371980, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "categories_df = pd.read_csv(\"product_types.csv\")\n",
    "category_list = categories_df[\"category_name\"].tolist()\n",
    "print(\"Total categories loaded:\", len(category_list))\n",
    "print(\"Sample categories:\", category_list[:10])\n",
    "\n",
    "# 讀取 customers 檔案\n",
    "customer_df = pd.read_parquet('data/customers.parquet')\n",
    "print(customer_df['club_member_status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 500.00 MiB. GPU 0 has a total capacity of 23.65 GiB of which 230.25 MiB is free. Process 834212 has 13.76 GiB memory in use. Including non-PyTorch memory, this process has 9.66 GiB memory in use. Of the allocated memory 8.54 GiB is allocated by PyTorch, and 686.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Test New LLM #2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m user_categories \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d25f88aa139fdfc657\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT-shirt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSweater\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlazer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVest top\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJacket\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShirt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m }\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mget_items_from_categories\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_categories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustomer_df\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[14], line 56\u001b[0m, in \u001b[0;36mget_items_from_categories\u001b[0;34m(category_dict, user_info)\u001b[0m\n\u001b[1;32m     54\u001b[0m full_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<s>[INST] <<SYS>>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msystem_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m<</SYS>>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00muser_prompt\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [/INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(full_prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 增加 token 數以容納多個名稱\u001b[39;00m\n\u001b[1;32m     57\u001b[0m response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     58\u001b[0m response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[/INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/anaconda3/envs/web-mining/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/web-mining/lib/python3.10/site-packages/transformers/generation/utils.py:2465\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2457\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2458\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2459\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2460\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2461\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2462\u001b[0m     )\n\u001b[1;32m   2464\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2465\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2466\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2470\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2472\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2476\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2477\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2478\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2479\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2480\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2481\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2482\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/web-mining/lib/python3.10/site-packages/transformers/generation/utils.py:3434\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3432\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3434\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3436\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3437\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3438\u001b[0m     outputs,\n\u001b[1;32m   3439\u001b[0m     model_kwargs,\n\u001b[1;32m   3440\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3441\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/web-mining/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/web-mining/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/web-mining/lib/python3.10/site-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/web-mining/lib/python3.10/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/anaconda3/envs/web-mining/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/web-mining/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:837\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n\u001b[1;32m    836\u001b[0m slice_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m-\u001b[39mlogits_to_keep, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(logits_to_keep, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m logits_to_keep\n\u001b[0;32m--> 837\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/web-mining/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/web-mining/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/web-mining/lib/python3.10/site-packages/accelerate/hooks.py:171\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 171\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/anaconda3/envs/web-mining/lib/python3.10/site-packages/accelerate/hooks.py:361\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    358\u001b[0m         ):\n\u001b[1;32m    359\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 361\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    371\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    372\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/web-mining/lib/python3.10/site-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 500.00 MiB. GPU 0 has a total capacity of 23.65 GiB of which 230.25 MiB is free. Process 834212 has 13.76 GiB memory in use. Including non-PyTorch memory, this process has 9.66 GiB memory in use. Of the allocated memory 8.54 GiB is allocated by PyTorch, and 686.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "## Test New LLM #2\n",
    "user_categories = {\n",
    "    \"00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d25f88aa139fdfc657\": [\n",
    "        \"T-shirt\", \"Sweater\", \"Blazer\", \"Vest top\", \"Jacket\", \"Shirt\"\n",
    "    ],\n",
    "    # \"0000423b00ade91418cceaf3b26c6af3dd342b51fd051eec9c12fb36984420fa\": [\n",
    "    #     \"Dress\", \"Cardigan\", \"Bikini top\", \"Swimsuit\", \"Vest top\", \"Dress\"\n",
    "    # ]\n",
    "}\n",
    "\n",
    "print(get_items_from_categories(user_categories, customer_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test Category Prefiltering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Session Enrichment\n",
    "\n",
    "This block is only for demonstration, not real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d25f88aa139fdfc657, History: T-shirt Top Jacket Vest top Sweater Blazer\n",
      "\n",
      "Top categories: ['Vest top', 'T-shirt', 'Sweater', 'Blazer', 'Jacket', 'Tailored Waistcoat', 'Swimwear top', 'Hoodie', 'Shirt', 'Garment Set', 'Outdoor Waistcoat', 'Polo shirt', 'Bodysuit', 'Bikini top', 'Swimsuit', 'Swimwear bottom', 'Swimwear set', 'Clothing mist', 'Zipper head', 'Robe']\n",
      "\n",
      "LLM raw output: [\"T-shirt\", \"Sweater\", \"Blazer\", \"Jacket\", \"Vest top\", \"Hoodie\", \"Shirt\", \"Garment Set\", \"Outdoor Waistcoat\"] \n",
      "\n",
      "End of the output\n",
      "Selected Categories: ['T-shirt', 'Sweater', 'Blazer', 'Jacket', 'Vest top', 'Hoodie', 'Shirt', 'Garment Set', 'Outdoor Waistcoat']\n",
      "\n",
      "Raw item LLM output: \n",
      " Sure, here's a realistic product name for a T-shirt that belongs to the T-shirt category, is appropriate for Spring, and has a realistic brand name and product description:\n",
      "\n",
      "\"Blooming Blossom Tee by FreshFit\"\n",
      "Extracted:  \"Blooming Blossom Tee by FreshFit\"\n",
      "Raw item LLM output: \n",
      " Here is a realistic product name for a Spring sweater:\n",
      "\n",
      "\"Blossomlight Pullover\"\n",
      "Extracted:  \"Blossomlight Pullover\"\n",
      "Raw item LLM output: \n",
      " Sure, here's a realistic product name for a blazer that belongs to the Blazer category, is appropriate for Spring, and has a realistic brand name and product description:\n",
      "\n",
      "Manson Spring Breeze Blazer\n",
      "\n",
      "This product name suggests a lightweight, breathable blazer perfect for Spring weather. The brand name \"Manson\" implies a high-quality, stylish product, and the product description \"Spring Breeze\" evokes a sense of freshness and renewal.\n",
      "Extracted:  This product name suggests a lightweight, breathable blazer perfect for Spring weather. The brand name \"Manson\" implies a high-quality, stylish product, and the product description \"Spring Breeze\" evokes a sense of freshness and renewal.\n",
      "User: 0000423b00ade91418cceaf3b26c6af3dd342b51fd051eec9c12fb36984420fa, History: Dress Dress Cardigan Bikini top Swimsuit Vest top\n",
      "\n",
      "Top categories: ['Swimwear top', 'Bikini top', 'Vest top', 'Swimsuit', 'Swimwear bottom', 'Swimwear set', 'Bodysuit', 'Dress', 'Tailored Waistcoat', 'Night gown', 'Sweater', 'Garment Set', 'Cardigan', 'Costumes', 'Jacket', 'T-shirt', 'Outdoor Waistcoat', 'Underwear body', 'Robe', 'Hoodie']\n",
      "\n",
      "LLM raw output: [\"Swimwear top\", \"Bikini top\", \"Vest top\", \"Swimsuit\", \"Swimwear bottom\", \"Swimwear set\", \"Bodysuit\", \"Dress\", \"Cardigan\"] \n",
      "\n",
      "End of the output\n",
      "Selected Categories: ['Swimwear top', 'Bikini top', 'Vest top', 'Swimsuit', 'Swimwear bottom', 'Swimwear set', 'Bodysuit', 'Dress', 'Cardigan']\n",
      "\n",
      "Raw item LLM output: \n",
      " Sure, I'd be happy to help! Here's a realistic product name for a Swimwear top in the Spring season:\n",
      "\n",
      "\"SUNKISSED BREEZE TOP\"\n",
      "Extracted:  \"SUNKISSED BREEZE TOP\"\n",
      "Raw item LLM output: \n",
      " Sure, here's a realistic product name for a Bikini top that belongs to the Bikini top category, is appropriate for Spring, and has a realistic brand name and product description:\n",
      "\n",
      "\"SUNSET SURFER in Bloom\" by Beachside Babe\n",
      "\n",
      "This name captures the essence of a bikini top that is perfect for Spring, with a brand name that evokes a carefree and sun-kissed vibe. The product description \"in Bloom\" suggests a delicate, flowy design that is perfect for the season.\n",
      "Extracted:  This name captures the essence of a bikini top that is perfect for Spring, with a brand name that evokes a carefree and sun-kissed vibe. The product description \"in Bloom\" suggests a delicate, flowy design that is perfect for the season.\n",
      "Raw item LLM output: \n",
      " Here is a realistic product name for a Vest top that belongs to the Spring season:\n",
      "\n",
      "Blossom Vest\n",
      "\n",
      "Brand Name: Bloom & Blossom\n",
      "\n",
      "Product Description: This lightweight Vest top is perfect for Spring weather. Made with breathable fabrics and a floral print, it's a stylish and comfortable addition to any outfit.\n",
      "Extracted:  Product Description: This lightweight Vest top is perfect for Spring weather. Made with breathable fabrics and a floral print, it's a stylish and comfortable addition to any outfit.\n",
      "Enriched Session: {'00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d25f88aa139fdfc657': [841260003, 887593002, 890498002, 795440001, 859416011, '\"Blooming Blossom Tee by FreshFit\"', '\"Blossomlight Pullover\"', 'This product name suggests a lightweight, breathable blazer perfect for Spring weather. The brand name \"Manson\" implies a high-quality, stylish product, and the product description \"Spring Breeze\" evokes a sense of freshness and renewal.', 568601043], '0000423b00ade91418cceaf3b26c6af3dd342b51fd051eec9c12fb36984420fa': [759191008, 800436010, 814686001, 590928022, 698276006, '\"SUNKISSED BREEZE TOP\"', 'This name captures the essence of a bikini top that is perfect for Spring, with a brand name that evokes a carefree and sun-kissed vibe. The product description \"in Bloom\" suggests a delicate, flowy design that is perfect for the season.', \"Product Description: This lightweight Vest top is perfect for Spring weather. Made with breathable fabrics and a floral print, it's a stylish and comfortable addition to any outfit.\", 749699013]}\n",
      "執行時間：1516.4926 秒\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "start_time = time.time()\n",
    "user_session = {\n",
    "    \"00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d25f88aa139fdfc657\": [841260003, 887593002, 890498002, 795440001, 859416011, 568601043],\n",
    "    \"0000423b00ade91418cceaf3b26c6af3dd342b51fd051eec9c12fb36984420fa\": [759191008, 800436010, 814686001, 590928022, 698276006, 749699013],\n",
    "}\n",
    "\n",
    "new_session = enrich_user_session(user_session, customer_df, category_list, n=3, max_history_length=9)\n",
    "print(\"Enriched Session:\", new_session)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"執行時間：{elapsed_time:.4f} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw item LLM output: \n",
      " Sure, I'd be happy to help! Based on the information provided, here is a realistic product name that belongs to the Top category and is appropriate for Spring:\n",
      "\n",
      "Aerin Ascend Tank\n"
     ]
    }
   ],
   "source": [
    "user_info = get_user_info(\"00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d25f88aa139fdfc657\", customer_df)\n",
    "\n",
    "raw_item = get_item_from_category('Top', user_info)\n",
    "print(\"Raw item LLM output: \\n\", raw_item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web-mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
