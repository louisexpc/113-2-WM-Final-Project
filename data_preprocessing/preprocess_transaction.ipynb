{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70677000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path as path\n",
    "\n",
    "def filter_cold_start_articles(df: pd.DataFrame, min_purchases: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove cold-start articles based on minimum interaction threshold.\n",
    "\n",
    "    Args:\n",
    "    - df: DataFrame, must contain column 'article_id'. \n",
    "          Typically includes [t_dat, customer_id, article_id, price, sales_channel_id]\n",
    "    - min_purchases : int, default 5. The minimum number of total purchases an article must have to be retained in the dataset.\n",
    "\n",
    "    Return:\n",
    "    - filtered_df : DataFrame containing only the transactions where article_id has appeared at least `min_purchases` times. Index is reset.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    article_counts = df.groupby('article_id')['article_id'].transform('count')\n",
    "\n",
    "    return df[article_counts >= min_purchases].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def filter_weeks_length(\n",
    "    df: pd.DataFrame,\n",
    "    weeks: int = 24,\n",
    "    min_purchases: int = 4,\n",
    "    max_purchase: int = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter user transactions based on their last active date, minimum purchase count,\n",
    "    and optionally cap the number of retained purchases per user to the last `max_purchase` entries.\n",
    "\n",
    "    Args:\n",
    "    - df             : DataFrame, 必須包含 [t_dat, customer_id, article_id, price, sales_channel_id]\n",
    "    - weeks          : int, default 24. 保留從最後一筆交易往回推 weeks 週的資料\n",
    "    - min_purchases  : int, default 4. 最少交易筆數，否則整個 user 會被過濾掉\n",
    "    - max_purchase   : int or None. 若不為 None，對於每個 user 最多保留最後 max_purchase 筆交易\n",
    "\n",
    "    Return:\n",
    "    - filtered_df : 經過篩選、上限控制後，並依原始順序排序、重設 index 的 DataFrame\n",
    "    \"\"\"\n",
    "    # 保留原始 index 用於最後還原\n",
    "    df2 = df.copy()\n",
    "    df2['t_dat'] = pd.to_datetime(df2['t_dat'])\n",
    "    df2['customer_id'] = df2['customer_id'].astype('category')\n",
    "\n",
    "    # 1. 計算每位 user 的最後交易日、交易筆數\n",
    "    last_date  = df2.groupby('customer_id')['t_dat'].transform('max')\n",
    "    row_count  = df2.groupby('customer_id')['t_dat'].transform('size')\n",
    "    start_date = last_date - np.timedelta64(weeks*7, 'D')\n",
    "\n",
    "    # 2. 時間窗 & min_purchases 篩選\n",
    "    mask = (\n",
    "        (df2['t_dat'] >= start_date) &\n",
    "        (df2['t_dat'] <= last_date) &\n",
    "        (row_count >= min_purchases)\n",
    "    )\n",
    "    filtered = df2[mask]\n",
    "\n",
    "    # 3. 若需上限，僅對超過 max_purchase 的 user 做排序 & 截斷\n",
    "    if max_purchase is not None:\n",
    "        # 計算各 user 在時間窗內的交易數\n",
    "        counts = filtered.groupby('customer_id').size()\n",
    "        users_over = counts[counts > max_purchase].index\n",
    "\n",
    "        # 分組處理：超過上限的 user vs 不超過的 user\n",
    "        df_over = filtered[filtered['customer_id'].isin(users_over)]\n",
    "        df_rest = filtered[~filtered['customer_id'].isin(users_over)]\n",
    "\n",
    "        # 僅對超限者做倒序排名並截斷\n",
    "        df_over = df_over.sort_values(['customer_id','t_dat'], ascending=[True, False])\n",
    "        df_over['rank'] = df_over.groupby('customer_id').cumcount()\n",
    "        df_over = df_over[df_over['rank'] < max_purchase].drop(columns='rank')\n",
    "\n",
    "        # 合併、還原\n",
    "        filtered = pd.concat([df_over, df_rest], ignore_index=False)\n",
    "\n",
    "    # 4. 還原成原始順序、重設 index\n",
    "    filtered = filtered.sort_index().reset_index(drop=True)\n",
    "    return filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dce9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame:\n",
      "  customer_id article_id  price  sales_channel_id      t_dat\n",
      "0           A       art0     10                 1 2025-05-18\n",
      "1           A       art1     11                 1 2025-05-11\n",
      "2           A       art2     12                 1 2025-05-04\n",
      "3           C     c_art0     30                 1 2025-05-18\n",
      "4           C     c_art1     31                 1 2025-05-11\n",
      "\n",
      "All tests passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_48380\\3348506245.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  last_date  = df2.groupby('customer_id')['t_dat'].transform('max')\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_48380\\3348506245.py:17: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  row_count  = df2.groupby('customer_id')['t_dat'].transform('size')\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_48380\\3348506245.py:26: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  counts = filtered.groupby('customer_id').size()\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_48380\\3348506245.py:31: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_over['rank'] = df_over.groupby('customer_id').cumcount()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Unit Test\n",
    "def filter_weeks_length(\n",
    "    df: pd.DataFrame,\n",
    "    weeks: int = 24,\n",
    "    min_purchases: int = 4,\n",
    "    max_purchase: int = None\n",
    ") -> pd.DataFrame:\n",
    "    df2 = df.copy()\n",
    "    df2['t_dat'] = pd.to_datetime(df2['t_dat'])\n",
    "    df2['customer_id'] = df2['customer_id'].astype('category')\n",
    "    last_date  = df2.groupby('customer_id')['t_dat'].transform('max')\n",
    "    row_count  = df2.groupby('customer_id')['t_dat'].transform('size')\n",
    "    start_date = last_date - np.timedelta64(weeks*7, 'D')\n",
    "    mask = (\n",
    "        (df2['t_dat'] >= start_date) &\n",
    "        (df2['t_dat'] <= last_date) &\n",
    "        (row_count >= min_purchases)\n",
    "    )\n",
    "    filtered = df2[mask]\n",
    "    if max_purchase is not None:\n",
    "        counts = filtered.groupby('customer_id').size()\n",
    "        users_over = counts[counts > max_purchase].index\n",
    "        df_over = filtered[filtered['customer_id'].isin(users_over)]\n",
    "        df_rest = filtered[~filtered['customer_id'].isin(users_over)]\n",
    "        df_over = df_over.sort_values(['customer_id','t_dat'], ascending=[True, False])\n",
    "        df_over['rank'] = df_over.groupby('customer_id').cumcount()\n",
    "        df_over = df_over[df_over['rank'] < max_purchase].drop(columns='rank')\n",
    "        filtered = pd.concat([df_over, df_rest], ignore_index=False)\n",
    "    return filtered.sort_index().reset_index(drop=True)\n",
    "\n",
    "today = datetime(2025, 5, 18)\n",
    "data = []\n",
    "\n",
    "for i in range(6):\n",
    "    data.append({\n",
    "        'customer_id': 'A',\n",
    "        'article_id': f'art{i}',\n",
    "        'price': 10+i,\n",
    "        'sales_channel_id': 1,\n",
    "        't_dat': today - timedelta(days=7*i)\n",
    "    })\n",
    "\n",
    "data.append({\n",
    "    'customer_id': 'B',\n",
    "    'article_id': 'b_art',\n",
    "    'price': 20,\n",
    "    'sales_channel_id': 1,\n",
    "    't_dat': today\n",
    "})\n",
    "\n",
    "for i in range(2):\n",
    "    data.append({\n",
    "        'customer_id': 'C',\n",
    "        'article_id': f'c_art{i}',\n",
    "        'price': 30+i,\n",
    "        'sales_channel_id': 1,\n",
    "        't_dat': today - timedelta(days=7*i)\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "filtered = filter_weeks_length(df, weeks=4, min_purchases=2, max_purchase=3)\n",
    "\n",
    "\n",
    "print(\"Filtered DataFrame:\")\n",
    "print(filtered)\n",
    "\n",
    "assert set(filtered['customer_id']) == {'A', 'C'}, \"Only users A and C should remain\"\n",
    "assert len(filtered[filtered['customer_id']=='A']) == 3, \"User A should have exactly 3 records\"\n",
    "assert len(filtered[filtered['customer_id']=='C']) == 2, \"User C should have 2 records\"\n",
    "\n",
    "print(\"\\nAll tests passed!\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7fee216",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"main\"\"\"\n",
    "trans = pd.read_csv(r\"transactions_train_mapping.csv\",\n",
    "                 parse_dates=['t_dat'],\n",
    "                 dtype={\n",
    "                     'customer_id':'int',\n",
    "                     'article_id': 'int',\n",
    "                     'price':'float',\n",
    "                     'sales_channel_id':'int'\n",
    "                 })\n",
    "\n",
    "ARTICLE = path.join(\"articles_mapping.csv\")\n",
    "article_dtype = {\n",
    "    'article_id':\"int\",\n",
    "    'detail_desc':\"category\"\n",
    "}\n",
    "\n",
    "article = pd.read_csv(ARTICLE,usecols=['article_id','detail_desc'],dtype=article_dtype,engine='pyarrow')\n",
    "\n",
    "\"\"\" Remove the transaction record of Missing desc articles\"\"\"\n",
    "valid_ids = article.loc[article['detail_desc'].notnull(), 'article_id']\n",
    "trans = trans[trans['article_id'].isin(valid_ids)]\n",
    "trans.to_csv(\"transactions_train_mapping_clean.csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d2cf1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_48380\\292377321.py:50: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  last_date  = df2.groupby('customer_id')['t_dat'].transform('max')\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_48380\\292377321.py:51: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  row_count  = df2.groupby('customer_id')['t_dat'].transform('size')\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_48380\\292377321.py:65: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  counts = filtered.groupby('customer_id').size()\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_48380\\292377321.py:74: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_over['rank'] = df_over.groupby('customer_id').cumcount()\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_48380\\292377321.py:50: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  last_date  = df2.groupby('customer_id')['t_dat'].transform('max')\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_48380\\292377321.py:51: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  row_count  = df2.groupby('customer_id')['t_dat'].transform('size')\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_48380\\292377321.py:65: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  counts = filtered.groupby('customer_id').size()\n",
      "C:\\Users\\louislin\\AppData\\Local\\Temp\\ipykernel_48380\\292377321.py:74: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_over['rank'] = df_over.groupby('customer_id').cumcount()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Filter length 3 : retain ratio (1006003 : 1361469) , remove: 355466\n",
      "After Filter length 5 : retain ratio (859243 : 1361469) , remove: 502226\n"
     ]
    }
   ],
   "source": [
    "# trans_remove_cold.to_csv(\"transactions_5.csv\",index=False)\n",
    "# trans_minLen_4.to_csv(\"transactions_5_4.csv\",index=False)\n",
    "# trans_minLen_6.to_csv(\"transactions_5_6.csv\",index=False)\n",
    "\"\"\"Remove Cold Start articles in transactions\"\"\"\n",
    "trans_remove_cold = filter_cold_start_articles(trans,min_purchases = 5)\n",
    "origin_cust_sum = trans_remove_cold['customer_id'].nunique()\n",
    "\n",
    "\"\"\"Filtering date(last 24 weeks) and session lengths(min = [4,6])\"\"\"\n",
    "trans_minLen_4 = filter_weeks_length(trans_remove_cold, weeks=24, min_purchases = 4, max_purchase= 30)\n",
    "min4_cust_sum = trans_minLen_4['customer_id'].nunique()\n",
    "\n",
    "trans_minLen_6 = filter_weeks_length(trans_remove_cold, weeks=24, min_purchases = 6 , max_purchase= 30)\n",
    "min6_cust_sum = trans_minLen_6['customer_id'].nunique()\n",
    "\n",
    "print(f\"After Filter length 3 : retain ratio ({min4_cust_sum} : {origin_cust_sum}) , remove: {origin_cust_sum-min4_cust_sum}\")\n",
    "print(f\"After Filter length 5 : retain ratio ({min6_cust_sum} : {origin_cust_sum}) , remove: {origin_cust_sum-min6_cust_sum}\")\n",
    "\n",
    "trans_remove_cold.to_csv(\"transactions_5_mapping.csv\",index=False)\n",
    "trans_minLen_4.to_csv(\"transactions_5_4_30_mapping.csv\",index=False)\n",
    "trans_minLen_6.to_csv(\"transactions_5_6_30_mapping.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
